import streamlit as st
import os
import time
import io
from openai import AzureOpenAI
from dotenv import load_dotenv

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ë° ê²€ì¦
required_env_vars = {
    "AZURE_OAI_ENDPOINT": os.getenv("AZURE_OAI_ENDPOINT"),
    "AZURE_OAI_KEY": os.getenv("AZURE_OAI_KEY"),
    "SEARCH_ENDPOINT": os.getenv("SEARCH_ENDPOINT"),
    "SEARCH_KEY": os.getenv("SEARCH_KEY"),
}

missing_vars = [key for key, value in required_env_vars.items() if not value]

if missing_vars:
    st.error(f"âŒ ë‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_vars)}")
    st.info("""
    ğŸ’¡ í•´ê²° ë°©ë²•:
    1. í”„ë¡œì íŠ¸ í´ë”ì— .env íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    2. .env íŒŒì¼ì— ë‹¤ìŒ ê°’ë“¤ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸:
       - AZURE_OAI_ENDPOINT=https://your-resource.openai.azure.com/
       - AZURE_OAI_KEY=your-api-key
       - AZURE_OAI_DEPLOYMENT=your-deployment-name
       - SEARCH_ENDPOINT=https://your-search.search.windows.net
       - SEARCH_KEY=your-search-key
    3. ê°’ì— ê³µë°±ì´ë‚˜ ë”°ì˜´í‘œê°€ ì—†ëŠ”ì§€ í™•ì¸
    4. ìì„¸í•œ ë‚´ìš©ì€ TROUBLESHOOTING.md íŒŒì¼ì„ ì°¸ê³ í•˜ì„¸ìš”
    """)
    st.code("""
# .env íŒŒì¼ ì˜ˆì‹œ
AZURE_OAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OAI_KEY=abc123def456...
AZURE_OAI_DEPLOYMENT=gpt-4o-mini
SEARCH_ENDPOINT=https://your-search.search.windows.net
SEARCH_KEY=search-key-here
    """, language="bash")
    st.stop()

# Endpoint í˜•ì‹ ê²€ì¦
endpoint = os.getenv("AZURE_OAI_ENDPOINT")
if endpoint and not endpoint.startswith("https://"):
    st.error("âŒ AZURE_OAI_ENDPOINTëŠ” https://ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.")
    st.info(f"í˜„ì¬ ê°’: {endpoint}")
    st.stop()

if endpoint and ".openai.azure.com" not in endpoint:
    st.warning("âš ï¸ AZURE_OAI_ENDPOINT í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”. (ì˜ˆ: https://your-resource.openai.azure.com/)")

st.set_page_config(
    page_title="ë°˜ë„ì²´ ê³µì • ì „ë¬¸ê°€ ì±—ë´‡",
    page_icon="ğŸ”¬",
    layout="wide"
)

st.title("ğŸ”¬ ë°˜ë„ì²´ ê³µì • í•™ìŠµ ë„ìš°ë¯¸ SEMI(ì„ë¯¸)")
st.caption("ğŸ’¡ í•™ë¶€ìƒì„ ìœ„í•œ AI ê¸°ë°˜ ë°˜ë„ì²´ ê³µì • ì´ë¡  & ì‹œê°í™” ì±—ë´‡")

# 2. Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = AzureOpenAI(
    azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT"),
    api_key=os.getenv("AZURE_OAI_KEY"),
    api_version="2024-05-01-preview"
)

# 3. Azure AI Search ì„¤ì •
SEARCH_ENDPOINT = os.getenv("SEARCH_ENDPOINT")
SEARCH_KEY = os.getenv("SEARCH_KEY")
SEARCH_INDEX = "semicon-proc-rag"
DEPLOYMENT_NAME = os.getenv("AZURE_OAI_DEPLOYMENT", "gpt-4o-mini")
EMBEDDING_DEPLOYMENT = os.getenv("AZURE_EMBEDDING_DEPLOYMENT", "text-embedding-ada-002")

# 4. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "assistant_id" not in st.session_state:
    st.session_state.assistant_id = None
if "thread_id" not in st.session_state:
    st.session_state.thread_id = None

# 5. ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    use_rag = st.checkbox("RAG ê²€ìƒ‰ í™œì„±í™”", value=True, help="ë°˜ë„ì²´ ê³µì • ì „ë¬¸ ì§€ì‹ í™œìš©")
    use_code_interpreter = st.checkbox("ì½”ë“œ ì¸í„°í”„ë¦¬í„° í™œì„±í™”", value=True, help="ë°ì´í„° ì‹œê°í™” ë° ê³„ì‚°")
    
    st.divider()
    st.subheader("ğŸ’¡ ì‚¬ìš© ê°€ì´ë“œ")
    
    # íƒ­ìœ¼ë¡œ êµ¬ë¶„
    tab1, tab2 = st.tabs(["ğŸ” ì´ë¡  ì§ˆë¬¸", "ğŸ“Š ì‹œê°í™”"])
    
    with tab1:
        st.markdown("""
        **ë°˜ë„ì²´ ê³µì • ì´ë¡  ì§ˆë¬¸ ì˜ˆì‹œ:**
        
        ğŸ¯ **ê³µì • ì›ë¦¬**
        - "í¬í† ë¦¬ì†Œê·¸ë˜í”¼ ê³µì •ì˜ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ì¤˜"
        - "ìŠµì‹ ì—ì¹­ê³¼ ê±´ì‹ ì—ì¹­ì˜ ì°¨ì´ëŠ”?"
        - "CVDì™€ PVDì˜ ì¥ë‹¨ì ì„ ë¹„êµí•´ì¤˜"
        
        ğŸ“ **ê³µì • íŒŒë¼ë¯¸í„°**
        - "CMP ê³µì •ì˜ ì£¼ìš” íŒŒë¼ë¯¸í„°ëŠ” ë­ì•¼?"
        - "ì´ì˜¨ì£¼ì…ì—ì„œ ë„ì¦ˆì™€ ì—ë„ˆì§€ì˜ ì—­í• ì€?"
        - "í”Œë¼ì¦ˆë§ˆ ì—ì¹­ì˜ ì„ íƒë¹„ë€?"
        
        ğŸ”¬ **ì‹¬í™” ì§ˆë¬¸**
        - "EUV ë¦¬ì†Œê·¸ë˜í”¼ê°€ ArFë³´ë‹¤ ì¢‹ì€ ì´ìœ ëŠ”?"
        - "damascene ê³µì •ì„ ì„¤ëª…í•´ì¤˜"
        - "ì—´ì‚°í™”ì™€ CVD ì‚°í™”ë§‰ì˜ ì°¨ì´ëŠ”?"
        """)
    
    with tab2:
        st.markdown("""
        **ì‹œê°í™” ìš”ì²­ ì˜ˆì‹œ (ìˆ˜ì¹˜ í¬í•¨):**
        
        ğŸ“Š **ë§‰ëŒ€ ê·¸ë˜í”„**
        ```
        ë°˜ë„ì²´ ì£¼ìš” ê³µì •ì˜ ì²˜ë¦¬ ì‹œê°„ì„ 
        ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ ê·¸ë ¤ì¤˜.
        
        - Photolithography: 45ë¶„
        - CVD: 30ë¶„
        - Etching: 25ë¶„
        - CMP: 20ë¶„
        ```
        
        ğŸ“ˆ **êº¾ì€ì„  ê·¸ë˜í”„**
        ```
        ì˜¨ë„ì— ë”°ë¥¸ CVD ì¦ì°©ë¥  ë³€í™”ë¥¼
        êº¾ì€ì„  ê·¸ë˜í”„ë¡œ ê·¸ë ¤ì¤˜.
        
        300Â°C: 10 nm/min
        500Â°C: 30 nm/min
        700Â°C: 60 nm/min
        ```
        
        ğŸ¥§ **íŒŒì´ ì°¨íŠ¸**
        ```
        ë°˜ë„ì²´ ì œì¡° ê³µì •ë³„ ë¹„ìš© ë¶„í¬ë¥¼
        íŒŒì´ ì°¨íŠ¸ë¡œ ê·¸ë ¤ì¤˜.
        
        - Lithography: 35%
        - Etching: 25%
        - Deposition: 20%
        - Others: 20%
        ```
        
        ğŸ’¡ **Tip:** ê·¸ë˜í”„ ë ˆì´ë¸”ì€ ì˜ë¬¸ìœ¼ë¡œ 
        í‘œì‹œë˜ë©°, ì„¤ëª…ì€ í•œê¸€ë¡œ ì œê³µë©ë‹ˆë‹¤.
        """)
    
    st.divider()
    
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.messages = []
        st.session_state.assistant_id = None
        st.session_state.thread_id = None
        st.rerun()
    
    st.caption("ğŸ“ í•™ë¶€ìƒì„ ìœ„í•œ ë°˜ë„ì²´ ê³µì • í•™ìŠµ ë„ìš°ë¯¸")

# 6. ê¸°ì¡´ ëŒ€í™” ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if "images" in message:
            for img in message["images"]:
                st.image(io.BytesIO(img), use_column_width=True)

# 7. ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ë°˜ë„ì²´ ê³µì •ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”! (ì˜ˆ: í¬í† ë¦¬ì†Œê·¸ë˜í”¼ë€ ë­ì•¼?)"):
    # (1) ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ & ì €ì¥
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # (2) RAG ê¸°ë°˜ Chat Completions ì‘ë‹µ
    with st.chat_message("assistant"):
        try:
            # RAGìš© ë©”ì‹œì§€ êµ¬ì„±
            if use_rag:
                # Azure AI Searchë¥¼ data sourceë¡œ ì‚¬ìš©
                response = client.chat.completions.create(
                    model=DEPLOYMENT_NAME,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ í•™ë¶€ìƒì„ ìœ„í•œ ë°˜ë„ì²´ ê³µì • í•™ìŠµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. í•™ë¶€ ìˆ˜ì—… ìˆ˜ì¤€ì˜ ë°˜ë„ì²´ ê³µì • ì´ë¡ ì„ ì‰½ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”. ì „ë¬¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” ì²˜ìŒì— ê°„ë‹¨í•œ ì„¤ëª…ì„ ë§ë¶™ì´ê³ , ë³µì¡í•œ ê°œë…ì€ ë‹¨ê³„ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”. í•™ìƒë“¤ì´ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ì˜ˆì‹œì™€ ë¹„ìœ ë¥¼ í™œìš©í•˜ì„¸ìš”."},
                        *[{"role": m["role"], "content": m["content"]} 
                          for m in st.session_state.messages]
                    ],
                    extra_body={
                        "data_sources": [
                            {
                                "type": "azure_search",
                                "parameters": {
                                    "endpoint": SEARCH_ENDPOINT,
                                    "index_name": SEARCH_INDEX,
                                    "query_type": "vector",
                                    "in_scope": True,
                                    "role_information": "ë‹¹ì‹ ì€ í•™ë¶€ìƒì„ ìœ„í•œ ë°˜ë„ì²´ ê³µì • í•™ìŠµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. í•™ë¶€ ìˆ˜ì¤€ì˜ ì´ë¡ ì„ ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.",
                                    "strictness": 3,
                                    "top_n_documents": 5,
                                    "authentication": {
                                        "type": "api_key",
                                        "key": SEARCH_KEY
                                    },
                                    "embedding_dependency": {
                                        "type": "deployment_name",
                                        "deployment_name": EMBEDDING_DEPLOYMENT
                                    }
                                }
                            }
                        ]
                    }
                )
            else:
                # ì¼ë°˜ ì‘ë‹µ
                response = client.chat.completions.create(
                    model=DEPLOYMENT_NAME,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ í•™ë¶€ìƒì„ ìœ„í•œ ë°˜ë„ì²´ ê³µì • í•™ìŠµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì‰½ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”."},
                        *[{"role": m["role"], "content": m["content"]} 
                          for m in st.session_state.messages]
                    ]
                )
            
            assistant_reply = response.choices[0].message.content
            
            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í‘œì‹œ (RAG ì‚¬ìš© ì‹œ)
            if use_rag and hasattr(response.choices[0].message, 'context'):
                context = response.choices[0].message.context
                if context and 'citations' in context:
                    with st.expander("ğŸ“„ ì°¸ì¡° ë¬¸ì„œ"):
                        for citation in context['citations']:
                            st.markdown(f"- {citation.get('title', 'Document')}")
            
            st.markdown(assistant_reply)
            st.session_state.messages.append({"role": "assistant", "content": assistant_reply})

        except Exception as e:
            st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.info("ğŸ’¡ .env íŒŒì¼ì˜ SEARCH_ENDPOINTì™€ SEARCH_KEYê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

    # (3) ì½”ë“œ ì¸í„°í”„ë¦¬í„° ì‹¤í–‰ ì—¬ë¶€ íŒë‹¨
    visualization_keywords = ["ê·¸ë˜í”„", "plot", "ì°¨íŠ¸", "ê·¸ë ¤ì¤˜", "ì‹œê°í™”", "í”Œë¡¯", "ë³´ì—¬ì¤˜", "ë¹„êµ", "ë¶„í¬"]
    calculation_keywords = ["ê³„ì‚°", "ì½”ë“œ", "ë¶„ì„", "í†µê³„", "í‰ê· ", "í•©ê³„"]
    
    needs_code_interpreter = use_code_interpreter and any(
        keyword in prompt.lower() for keyword in visualization_keywords + calculation_keywords
    )
    
    if needs_code_interpreter:
        with st.spinner("ğŸ–¥ï¸ ì½”ë“œ ì¸í„°í”„ë¦¬í„°ë¡œ ë¶„ì„ ì¤‘..."):
            try:
                # Assistants API ì¤€ë¹„
                if st.session_state.assistant_id is None:
                    assistant = client.beta.assistants.create(
                        model=DEPLOYMENT_NAME,
                        instructions="""You are a helpful assistant for undergraduate students learning semiconductor processes.

**CRITICAL FONT RULE:**
The code interpreter does NOT have Korean fonts. Use ONLY English for all graph text (titles, labels, legends).

**Your role:**
- Help students visualize and understand semiconductor process data
- Create clear, educational graphs
- Explain results in simple terms (in Korean in text, not graphs)

**For ALL visualizations:**

1. **Use English ONLY in graphs:**
   - Titles, axis labels, legends, annotations
   - Keep labels simple and clear for students

2. **Font settings (mandatory first):**
```python
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams['font.family'] = 'DejaVu Sans'
matplotlib.rcParams['axes.unicode_minus'] = False
```

3. **Common terms for students:**
   - í¬í† ë¦¬ì†Œê·¸ë˜í”¼ â†’ "Photolithography"
   - ì—ì¹­ â†’ "Etching"  
   - ì¦ì°© â†’ "Deposition"
   - ì´ì˜¨ì£¼ì… â†’ "Ion Implantation"
   - ê³µì • ì‹œê°„ â†’ "Process Time"
   - ì˜¨ë„ â†’ "Temperature"
   - ì••ë ¥ â†’ "Pressure"

4. **Graph style (educational & clear):**
```python
plt.figure(figsize=(10, 6))
plt.title('Clear Descriptive Title', fontsize=14, fontweight='bold')
plt.xlabel('X-axis Label (unit)', fontsize=12)
plt.ylabel('Y-axis Label (unit)', fontsize=12)
plt.grid(True, alpha=0.3, linestyle='--')
plt.legend(loc='best', fontsize=10)
plt.tight_layout()

# Add value labels on bars for clarity
for i, v in enumerate(values):
    plt.text(i, v, str(v), ha='center', va='bottom')
```

5. **Make it educational:**
   - Use clear, readable fonts (size 10-14)
   - Add gridlines for easy reading
   - Label data points when helpful
   - Use distinct colors
   - Include units in labels

**Remember:**
- Graphs: English only (clean display)
- Code comments: Can be Korean
- Explanations to student: Korean (easy to understand)

Example good title: "CVD Deposition Rate vs Temperature"
Example good label: "Processing Time (minutes)"
""",
                        tools=[{"type": "code_interpreter"}],
                        tool_resources={"code_interpreter": {"file_ids": []}},
                        temperature=0.3
                    )
                    st.session_state.assistant_id = assistant.id

                if st.session_state.thread_id is None:
                    thread = client.beta.threads.create()
                    st.session_state.thread_id = thread.id

                # ì‚¬ìš©ì ìš”ì²­ ì¶”ê°€ (RAG ì‘ë‹µ í¬í•¨)
                enhanced_prompt = f"""
                ì´ì „ ë‹µë³€: {assistant_reply}
                
                ì‚¬ìš©ì ìš”ì²­: {prompt}
                
                ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë°ì´í„° ì‹œê°í™” ë˜ëŠ” ê³„ì‚°ì„ ìˆ˜í–‰í•˜ì„¸ìš”.
                """
                
                client.beta.threads.messages.create(
                    thread_id=st.session_state.thread_id,
                    role="user",
                    content=enhanced_prompt
                )

                # ì‹¤í–‰
                run = client.beta.threads.runs.create(
                    thread_id=st.session_state.thread_id,
                    assistant_id=st.session_state.assistant_id
                )

                # ìƒíƒœ í´ë§
                max_wait = 60  # ìµœëŒ€ 60ì´ˆ ëŒ€ê¸°
                start_time = time.time()
                while True:
                    run = client.beta.threads.runs.retrieve(
                        thread_id=st.session_state.thread_id,
                        run_id=run.id
                    )
                    if run.status in ["queued", "in_progress"]:
                        if time.time() - start_time > max_wait:
                            st.warning("â±ï¸ ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            break
                        time.sleep(1)
                        continue
                    else:
                        break

                if run.status == "completed":
                    msgs = client.beta.threads.messages.list(thread_id=st.session_state.thread_id)
                    images = []
                    code_output = None
                    
                    for m in reversed(msgs.data):
                        if m.role == "assistant":
                            for c in m.content:
                                if c.type == "image_file":
                                    fid = c.image_file.file_id
                                    resp = client.files.content(fid)
                                    img_bytes = resp.read()
                                    images.append(img_bytes)
                                elif c.type == "text":
                                    code_output = c.text.value
                            break

                    if images or code_output:
                        with st.chat_message("assistant"):
                            st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼")
                            
                            if code_output:
                                st.markdown(code_output)
                            
                            if images:
                                st.markdown("#### ìƒì„±ëœ ì‹œê°í™”")
                                for idx, img in enumerate(images):
                                    st.image(io.BytesIO(img), caption=f"ë¶„ì„ ê²°ê³¼ {idx+1}", use_column_width=True)
                                
                                # ì´ë¯¸ì§€ë¥¼ ë©”ì‹œì§€ì— ì €ì¥
                                st.session_state.messages.append({
                                    "role": "assistant",
                                    "content": "ğŸ“Š ì‹œê°í™” ê²°ê³¼",
                                    "images": images
                                })
                    else:
                        st.info("â„¹ï¸ ì‹œê°í™” ê²°ê³¼ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                        
                elif run.status == "failed":
                    st.error(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {run.last_error.message if run.last_error else 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}")
                else:
                    st.warning(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ìƒíƒœ: {run.status}")
                    
            except Exception as e:
                st.error(f"âŒ ì½”ë“œ ì¸í„°í”„ë¦¬í„° ì˜¤ë¥˜: {str(e)}")

# 8. í‘¸í„°
st.divider()
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    st.caption("ğŸ“ ë°˜ë„ì²´ ê³µì • í•™ìŠµ ë„ìš°ë¯¸ | í•™ë¶€ìƒì„ ìœ„í•œ AI ê¸°ë°˜ í•™ìŠµ ë„êµ¬")
    st.caption("ğŸ’¡ RAG ê²€ìƒ‰ + ì½”ë“œ ì¸í„°í”„ë¦¬í„° ì‹œê°í™” | Powered by Azure OpenAI")

