
import streamlit as st
import os
import time
import io
from openai import AzureOpenAI
from dotenv import load_dotenv

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

st.title("ğŸ¤– ë‚˜ì˜ ì²« AI ì±—ë´‡ + ì½”ë“œ ì¸í„°í”„ë¦¬í„°")

# 2. Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = AzureOpenAI(
    azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT"),
    api_key=os.getenv("AZURE_OAI_KEY"),
    api_version="2024-05-01-preview"  # Assistants API ë²„ì „
)

# 3. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "assistant_id" not in st.session_state:
    st.session_state.assistant_id = None
if "thread_id" not in st.session_state:
    st.session_state.thread_id = None

# 4. ê¸°ì¡´ ëŒ€í™” ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    # (1) ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ & ì €ì¥
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # (2) ì¼ë°˜ Chat Completions ì‘ë‹µ
    with st.chat_message("assistant"):
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # Azure ë°°í¬ ì´ë¦„
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ]
        )
        assistant_reply = response.choices[0].message.content
        st.markdown(assistant_reply)

    st.session_state.messages.append({"role": "assistant", "content": assistant_reply})

    # (3) ì½”ë“œ ì¸í„°í”„ë¦¬í„° ì‹¤í–‰ ì—¬ë¶€ íŒë‹¨ (ê°„ë‹¨í•œ ì¡°ê±´)
    if any(keyword in prompt.lower() for keyword in ["ê·¸ë˜í”„", "plot", "ê·¸ë ¤ì¤˜", "ê³„ì‚°", "ì½”ë“œ"]):
        st.markdown("### ğŸ–¥ï¸ ì½”ë“œ ì¸í„°í”„ë¦¬í„° ì‹¤í–‰ ì¤‘...")
        # Assistants API ì¤€ë¹„
        if st.session_state.assistant_id is None:
            assistant = client.beta.assistants.create(
                model="gpt-4o-mini",
                instructions="ë„ˆëŠ” ì½”ë“œ ì¸í„°í”„ë¦¬í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë¶„ì„ ë„ìš°ë¯¸ì•¼.",
                tools=[{"type": "code_interpreter"}],
                tool_resources={"code_interpreter": {"file_ids": []}},
                temperature=0.7,
                top_p=1
            )
            st.session_state.assistant_id = assistant.id

        if st.session_state.thread_id is None:
            thread = client.beta.threads.create()
            st.session_state.thread_id = thread.id

        # ì‚¬ìš©ì ìš”ì²­ ì¶”ê°€
        client.beta.threads.messages.create(
            thread_id=st.session_state.thread_id,
            role="user",
            content=prompt
        )

        # ì‹¤í–‰
        run = client.beta.threads.runs.create(
            thread_id=st.session_state.thread_id,
            assistant_id=st.session_state.assistant_id
        )

        # ìƒíƒœ í´ë§
        while True:
            run = client.beta.threads.runs.retrieve(
                thread_id=st.session_state.thread_id,
                run_id=run.id
            )
            if run.status in ["queued", "in_progress"]:
                time.sleep(1)
                continue
            else:
                break

        if run.status == "completed":
            msgs = client.beta.threads.messages.list(thread_id=st.session_state.thread_id)
            images = []
            for m in reversed(msgs.data):
                if m.role == "assistant":
                    for c in m.content:
                        if c.type == "image_file":
                            fid = c.image_file.file_id
                            resp = client.files.content(fid)
                            img_bytes = resp.read()
                            images.append(img_bytes)
                    break

            if images:
                st.markdown("#### âœ… ìƒì„±ëœ ì´ë¯¸ì§€")
                for img in images:
                    st.image(io.BytesIO(img), caption="Code Interpreter Output", use_column_width=True)
            else:
                st.markdown("_ì´ë¯¸ì§€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤._")
        else:
            st.error(f"Run status: {run.status}")
